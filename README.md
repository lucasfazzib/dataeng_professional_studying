- ðŸ‘‹ Hi, Iâ€™m @lucasfazzib
- ðŸ‘€ This is a repo to save my study cases, tips, ideas to try to reach at the databricks professional certification.

- Design database and pipelines optimized for Databricks Lakehouse Platform
- Implement efficient incremental data processing to validate and enrich data driving business decisions and applications.
- Leverage Databricks native features for managing access to sensitive data.
- Manage code promotion, task orchestration, and production job monitoring using Databricks tools.


- Architecting for the Lakehouse
- Bronze Ingestion Patterns
- Promoting to Silver
- Gold query layer
- Storing data securely
- Propagating updates and deletes
- orchestration and scheduling


- MAIN GOAL
- Design and implement a multi-pipeline multi-hop architecture to enable the Lakehouse paradigm.

- Notebooks used on this study was available in this repo:
https://github.com/databricks-academy/advanced-data-engineering-with-databricks/releases/tag/v2.6.1


- I will use the Databricks Community to run the notebooks and do it for free.
- This resource from Databricks gives us:
    - Limited environment to run the notebooks.
    - Cluster with free 15 GB Memory: As a Community Edition user, your cluster will automatically terminate after an idle period of two hours.
